{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a90fefc4",
      "metadata": {
        "id": "a90fefc4"
      },
      "source": [
        "# üå± Soil Classification Challenge - Training\n",
        "This notebook covers the training pipeline for the Soil Classification Challenge. We will load the dataset, preprocess images, build and train a Convolutional Neural Network (CNN), and evaluate its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c45ae09",
      "metadata": {
        "id": "2c45ae09"
      },
      "source": [
        "## 1. üìö Importing Required Libraries\n",
        "We import all the required Python libraries for data handling, visualization, image processing, and building our machine learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2098a174",
      "metadata": {
        "id": "2098a174"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2f91bb9",
      "metadata": {
        "id": "e2f91bb9"
      },
      "source": [
        "## 2. üìÑ Loading Dataset\n",
        "We begin by loading the training labels CSV which contains image IDs and corresponding soil type labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fb673aa",
      "metadata": {
        "id": "1fb673aa"
      },
      "outputs": [],
      "source": [
        "csv_path = \"/content/soil_classification-2025/train_labels.csv\"\n",
        "train_df = pd.read_csv(csv_path)\n",
        "print(\"‚úÖ train_labels.csv loaded successfully.\")\n",
        "display(train_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84590449",
      "metadata": {
        "id": "84590449"
      },
      "source": [
        "## 3. üñºÔ∏è Viewing a Sample Image\n",
        "Let's load and visualize one sample image from the dataset to get a sense of the input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae9225f",
      "metadata": {
        "id": "cae9225f"
      },
      "outputs": [],
      "source": [
        "image_folder = \"/content/soil_classification-2025/train\"\n",
        "sample_row = train_df.iloc[0]\n",
        "img_path = os.path.join(image_folder, sample_row['image_id'])\n",
        "\n",
        "img = cv2.imread(img_path)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Label: {sample_row['soil_type']}\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4e73bee3",
      "metadata": {
        "id": "4e73bee3"
      },
      "source": [
        "## 4. üßπ Data Preprocessing\n",
        "In this step, we:\n",
        "- Encode categorical soil labels into numbers\n",
        "- Resize and normalize all images\n",
        "- Store them as NumPy arrays for model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "14e40651",
      "metadata": {
        "id": "14e40651"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE = 128\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label'] = label_encoder.fit_transform(train_df['soil_type'])\n",
        "\n",
        "print(\"Label mapping:\")\n",
        "for i, soil_type in enumerate(label_encoder.classes_):\n",
        "    print(f\"{i}: {soil_type}\")\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "for i in tqdm(range(len(train_df))):\n",
        "    row = train_df.iloc[i]\n",
        "    img_path = os.path.join(image_folder, row['image_id'])\n",
        "    try:\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        X.append(img)\n",
        "        y.append(row['label'])\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {row['image_id']}: {e}\")\n",
        "\n",
        "X = np.array(X) / 255.0\n",
        "y = np.array(y)\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(X)} images of shape {X[0].shape}\")\n",
        "\n",
        "# Save the label encoder for inference\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce1d6c41",
      "metadata": {
        "id": "ce1d6c41"
      },
      "source": [
        "## 5. üîÄ Train-Validation Split\n",
        "We split the dataset into training and validation sets to evaluate model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a70b2abc",
      "metadata": {
        "id": "a70b2abc"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "print(f\"‚úÖ Train size: {len(X_train)}, Validation size: {len(X_val)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "248ab745",
      "metadata": {
        "id": "248ab745"
      },
      "source": [
        "## 6. üèóÔ∏è Building the CNN Model\n",
        "We use a simple CNN architecture with convolutional and pooling layers followed by dense layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0bb6831f",
      "metadata": {
        "id": "0bb6831f"
      },
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
        "    MaxPooling2D(2,2),\n",
        "    Conv2D(64, (3,3), activation='relu'),\n",
        "    MaxPooling2D(2,2),\n",
        "    Flatten(),\n",
        "    Dropout(0.5),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(len(label_encoder.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4099f1ce",
      "metadata": {
        "id": "4099f1ce"
      },
      "source": [
        "## 7. üéØ Model Training\n",
        "Train the model for 10 epochs and monitor validation performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ebcd713c",
      "metadata": {
        "id": "ebcd713c"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('soil_classification_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe14671e",
      "metadata": {
        "id": "fe14671e"
      },
      "source": [
        "## 8. üìâ Training Performance\n",
        "Visualize accuracy and loss over training epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "470cd457",
      "metadata": {
        "id": "470cd457"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Val Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a9f4b0f",
      "metadata": {
        "id": "1a9f4b0f"
      },
      "source": [
        "## 9. üß™ Validation Evaluation\n",
        "Evaluate final performance on the validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e72ae7e",
      "metadata": {
        "id": "0e72ae7e"
      },
      "outputs": [],
      "source": [
        "loss, accuracy = model.evaluate(X_val, y_val)\n",
        "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}