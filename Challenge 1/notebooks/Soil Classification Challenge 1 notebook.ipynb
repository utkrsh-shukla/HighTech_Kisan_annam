{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90fefc4",
   "metadata": {},
   "source": [
    "# üå± Soil Classification Challenge - Part 1\n",
    "Welcome to the Soil Classification Challenge! In this notebook, we will walk through the entire machine learning workflow, from loading the dataset to submitting predictions for evaluation. This task involves classifying images of soil into different types using a Convolutional Neural Network (CNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c45ae09",
   "metadata": {},
   "source": [
    "## 1. üìö Importing Required Libraries\n",
    "In this section, we import all the required Python libraries for data handling, visualization, image processing, and building our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f91bb9",
   "metadata": {},
   "source": [
    "## 2. üìÑ Loading Dataset\n",
    "We begin by loading the training labels CSV which contains image IDs and corresponding soil type labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb673aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"/content/soil_classification-2025/train_labels.csv\"\n",
    "train_df = pd.read_csv(csv_path)\n",
    "print(\"‚úÖ train_labels.csv loaded successfully.\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84590449",
   "metadata": {},
   "source": [
    "## 3. üñºÔ∏è Viewing a Sample Image\n",
    "Let's load and visualize one sample image from the dataset to get a sense of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae9225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = \"/content/soil_classification-2025/train\"\n",
    "sample_row = train_df.iloc[0]\n",
    "img_path = os.path.join(image_folder, sample_row['image_id'])\n",
    "\n",
    "img = cv2.imread(img_path)\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label: {sample_row['soil_type']}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e73bee3",
   "metadata": {},
   "source": [
    "## 4. üßπ Data Preprocessing\n",
    "In this step, we:\n",
    "- Encode categorical soil labels into numbers\n",
    "- Resize and normalize all images\n",
    "- Store them as NumPy arrays for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e40651",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 128\n",
    "label_encoder = LabelEncoder()\n",
    "train_df['label'] = label_encoder.fit_transform(train_df['soil_type'])\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for i, soil_type in enumerate(label_encoder.classes_):\n",
    "    print(f\"{i}: {soil_type}\")\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in tqdm(range(len(train_df))):\n",
    "    row = train_df.iloc[i]\n",
    "    img_path = os.path.join(image_folder, row['image_id'])\n",
    "    try:\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            continue\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        X.append(img)\n",
    "        y.append(row['label'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {row['image_id']}: {e}\")\n",
    "\n",
    "X = np.array(X) / 255.0\n",
    "y = np.array(y)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(X)} images of shape {X[0].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1d6c41",
   "metadata": {},
   "source": [
    "## 5. üîÄ Train-Validation Split\n",
    "We split the dataset into training and validation sets to evaluate model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70b2abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"‚úÖ Train size: {len(X_train)}, Validation size: {len(X_val)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ab745",
   "metadata": {},
   "source": [
    "## 6. üèóÔ∏è Building the CNN Model\n",
    "We use a simple CNN architecture with convolutional and pooling layers followed by dense layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb6831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4099f1ce",
   "metadata": {},
   "source": [
    "## 7. üéØ Model Training\n",
    "Train the model for 10 epochs and monitor validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcd713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe14671e",
   "metadata": {},
   "source": [
    "## 8. üìâ Training Performance\n",
    "Visualize accuracy and loss over training epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470cd457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9f4b0f",
   "metadata": {},
   "source": [
    "## 9. üß™ Validation Evaluation\n",
    "Evaluate final performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e72ae7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Validation Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a88f7d",
   "metadata": {},
   "source": [
    "## 10. üßæ Test Data Prediction & Submission\n",
    "Make predictions on test images and create a submission CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed4332a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_dir = \"/content/soil_classification-2025/test\"\n",
    "test_images = []\n",
    "image_ids = []\n",
    "\n",
    "for img_name in tqdm(os.listdir(test_image_dir)):\n",
    "    img_path = os.path.join(test_image_dir, img_name)\n",
    "    try:\n",
    "        image = Image.open(img_path).convert('RGB').resize((IMG_SIZE, IMG_SIZE))\n",
    "        image = np.array(image) / 255.0\n",
    "        test_images.append(image)\n",
    "        image_ids.append(img_name)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {img_name}: {e}\")\n",
    "\n",
    "test_images = np.array(test_images)\n",
    "predictions = model.predict(test_images)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "predicted_labels = label_encoder.inverse_transform(predicted_classes)\n",
    "\n",
    "submission_df = pd.DataFrame({\n",
    "    'image_id': image_ids,\n",
    "    'soil_type': predicted_labels\n",
    "})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"‚úÖ Submission file created successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87647ba",
   "metadata": {},
   "source": [
    "## 11. üñºÔ∏è Visualizing Test Predictions\n",
    "Let's visualize some test images with predicted soil type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9347b497",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i in range(min(9, len(test_images))):\n",
    "    plt.subplot(3, 3, i+1)\n",
    "    plt.imshow(test_images[i])\n",
    "    plt.title(f\"Pred: {predicted_labels[i]}\")\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07898b3",
   "metadata": {},
   "source": [
    "## 12. ‚úÖ Conclusion\n",
    "- We successfully built and trained a CNN to classify soil images.\n",
    "- Achieved good validation accuracy.\n",
    "- Generated predictions for test data.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
