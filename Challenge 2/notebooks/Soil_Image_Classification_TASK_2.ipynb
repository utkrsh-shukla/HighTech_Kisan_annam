{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0gLAW-Uv1K7"
      },
      "source": [
        "# üå± Soil Image Classification Challenge - Annam.ai, IIT Ropar üå±\n",
        "\n",
        "This notebook implements a solution for the Soil Image Classification Challenge using a pre-trained ResNet18 model in PyTorch. The goal is to classify images as containing soil (label 1) or not (label 0). Let's dive in! üöÄ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqtNuv3iv1K8"
      },
      "source": [
        "## üìö Step 1: Import Libraries\n",
        "We start by importing the necessary libraries for data handling, model building, and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZtaxWhgv1K8"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import random_split\n",
        "from torchvision import transforms\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_6U2E4zv1K8"
      },
      "source": [
        "## üõ†Ô∏è Step 2: Set Up Paths\n",
        "Define the paths to the dataset directories and CSV files, and verify their existence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBQ6jXaTv1K8"
      },
      "outputs": [],
      "source": [
        "base_dir = \"/content/soil_competition-2025-2\"\n",
        "train_dir = os.path.join(base_dir, \"train\")\n",
        "test_dir = os.path.join(base_dir, \"test\")\n",
        "train_csv = os.path.join(base_dir, \"train_labels.csv\")\n",
        "test_csv = os.path.join(base_dir, \"test_ids.csv\")\n",
        "\n",
        "# Verify dataset\n",
        "print(\"Checking dataset files... üìÇ\")\n",
        "print(f\"Train CSV exists: {os.path.exists(train_csv)}\")\n",
        "print(f\"Test CSV exists: {os.path.exists(test_csv)}\")\n",
        "\n",
        "# Load train labels\n",
        "train_labels = pd.read_csv(train_csv)\n",
        "print(\"\\nTrain labels sample: üìã\")\n",
        "print(train_labels.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RS8C7cPgv1K9"
      },
      "source": [
        "## üñºÔ∏è Step 3: Define Data Preprocessing\n",
        "We define image transformations for training (with augmentation) and testing (without augmentation) to prepare images for ResNet18."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR9JapBGv1K9"
      },
      "outputs": [],
      "source": [
        "# Training transforms with augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Test transforms without augmentation\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IqUdbvfv1K9"
      },
      "source": [
        "## üìä Step 4: Create Dataset Classes\n",
        "Custom dataset classes are defined for loading training and test images, handling CSV files, and applying transformations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zEQj5en-v1K9"
      },
      "outputs": [],
      "source": [
        "class SoilDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.labels = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.labels.iloc[idx]['image_id'])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        label = self.labels.iloc[idx]['soil_label']\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, csv_file, img_dir, transform=None):\n",
        "        self.test_data = pd.read_csv(csv_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.test_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.img_dir, self.test_data.iloc[idx]['image_id'])\n",
        "        image = Image.open(img_name).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, self.test_data.iloc[idx]['image_id']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw1HG8nOv1K9"
      },
      "source": [
        "## üöö Step 5: Load Data\n",
        "Split the training data into training and validation sets, and create data loaders for batch processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNZLKWhyv1K9"
      },
      "outputs": [],
      "source": [
        "train_dataset = SoilDataset(train_csv, train_dir, train_transforms)\n",
        "train_size = int(0.8 * len(train_dataset))\n",
        "val_size = len(train_dataset) - train_size\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = TestDataset(test_csv, test_dir, test_transforms)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"Training samples: {len(train_subset)} üìà\")\n",
        "print(f\"Validation samples: {len(val_subset)} üìâ\")\n",
        "print(f\"Test samples: {len(test_dataset)} üß™\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nbAmi6wv1K9"
      },
      "source": [
        "## üëÄ Step 6: Visualize Sample Images\n",
        "Visualize a few training images to ensure the data is loaded correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0ZKtKlHv1K9"
      },
      "outputs": [],
      "source": [
        "def imshow(img, title):\n",
        "    img = img.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = std * img + mean\n",
        "    img = np.clip(img, 0, 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Display sample images\n",
        "images, labels = next(iter(train_loader))\n",
        "for i in range(3):\n",
        "    imshow(images[i], f\"Label: {labels[i].item()} (Soil) üåç\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_QOyMOBv1K-"
      },
      "source": [
        "## üß† Step 7: Define the Model\n",
        "Use a pre-trained ResNet18 model, modifying the final layer to output two classes (soil or not soil)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OS02Xz3Bv1K-"
      },
      "outputs": [],
      "source": [
        "model = models.resnet18(pretrained=True)\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: soil (1), not soil (0)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Model loaded on: {device} ‚öôÔ∏è\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bThb91Wv1K-"
      },
      "source": [
        "## üîß Step 8: Define Loss and Optimizer\n",
        "Set up the loss function (CrossEntropyLoss) and optimizer (Adam) for training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RI_VJV9lv1K-"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "253G5fTTv1K-"
      },
      "source": [
        "## üèãÔ∏è Step 9: Training Loop\n",
        "Train the model for a few epochs, tracking training and validation losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QntYL8_qv1K-"
      },
      "outputs": [],
      "source": [
        "num_epochs = 5  # Reduced for demo\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    train_losses.append(train_loss)\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            val_loss += criterion(outputs, labels).item()\n",
        "    val_loss /= len(val_loader)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f} üìä\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lWmayJjv1K-"
      },
      "source": [
        "## üìà Step 10: Plot Loss Curves\n",
        "Visualize the training and validation loss curves to assess model performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KI6r1rmKv1K-"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot(range(1, num_epochs+1), train_losses, label='Train Loss', color='blue')\n",
        "plt.plot(range(1, num_epochs+1), val_losses, label='Val Loss', color='orange')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training and Validation Loss üìâ')\n",
        "plt.legend()\n",
        "plt.savefig('loss_curves.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BupnXYP2v1K-"
      },
      "source": [
        "## üîç Step 11: Generate Test Predictions\n",
        "Make predictions on the test set and collect image IDs for the submission file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HF836JHjv1K-"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "predictions = []\n",
        "image_ids = []\n",
        "with torch.no_grad():\n",
        "    for images, img_ids in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "        image_ids.extend(img_ids)\n",
        "\n",
        "# Remove .jpg from image_ids\n",
        "image_ids = [img_id.replace('.jpg', '') for img_id in image_ids]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbrWdjZlv1K-"
      },
      "source": [
        "## üíæ Step 12: Create Submission File\n",
        "Save the predictions to a CSV file in the required format for Kaggle submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNrIvyRhv1K-"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame({\n",
        "    \"image_id\": image_ids,\n",
        "    \"soil_label\": predictions\n",
        "})\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\nSubmission file created: ‚úÖ\")\n",
        "print(submission.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-EXkRgav1K-"
      },
      "source": [
        "## üìù Notes\n",
        "- The model uses a pre-trained ResNet18 with transfer learning for efficiency. üß†\n",
        "- Training is limited to 5 epochs for demonstration; consider increasing for better performance. ‚è≥\n",
        "- Ensure the dataset paths are correct for your environment (e.g., `/content/soil_competition-2025-2`). üìÇ\n",
        "- The submission file (`submission.csv`) is saved in the working directory for Kaggle submission. üöÄ"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}