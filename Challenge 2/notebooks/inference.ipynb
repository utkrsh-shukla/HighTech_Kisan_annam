{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸŒ± Soil Image Classification Inference - Annam.ai, IIT Ropar ğŸŒ±\n\nThis notebook performs inference for the Soil Image Classification Challenge using a pre-trained ResNet18 model in PyTorch. It loads a trained model and generates predictions for the test set. Let's get started! ğŸš€"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“š Step 1: Import Libraries\nWe import the necessary libraries for data handling and model inference."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision import models\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ› ï¸ Step 2: Set Up Paths\nDefine the paths to the test dataset directory and CSV file, and verify their existence."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/content/soil_competition-2025-2\"\n",
    "test_dir = os.path.join(base_dir, \"test\")\n",
    "test_csv = os.path.join(base_dir, \"test_ids.csv\")\n",
    "\n",
    "# Verify dataset\n",
    "print(\"Checking dataset files... ğŸ“‚\")\n",
    "print(f\"Test CSV exists: {os.path.exists(test_csv)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ–¼ï¸ Step 3: Define Data Preprocessing\nWe define image transformations for testing (without augmentation) to prepare images for ResNet18."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test transforms without augmentation\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“Š Step 4: Create Test Dataset Class\nCustom dataset class for loading test images."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.test_data = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.test_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.test_data.iloc[idx]['image_id'])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.test_data.iloc[idx]['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸšš Step 5: Load Test Data\nCreate a data loader for the test dataset."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(test_csv, test_dir, test_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(f\"Test samples: {len(test_dataset)} ğŸ§ª\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ§  Step 6: Define and Load the Model\nLoad the pre-trained ResNet18 model and the saved weights."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 2)  # 2 classes: soil (1), not soil (0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load('soil_classifier.pth'))\n",
    "model.eval()\n",
    "print(f\"Model loaded on: {device} âš™ï¸\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ” Step 7: Generate Test Predictions\nMake predictions on the test set and collect image IDs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "image_ids = []\n",
    "with torch.no_grad():\n",
    "    for images, img_ids in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "        image_ids.extend(img_ids)\n",
    "\n",
    "# Remove .jpg from image_ids\n",
    "image_ids = [img_id.replace('.jpg', '') for img_id in image_ids]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ’¾ Step 8: Create Submission File\nSave the predictions to a CSV file for Kaggle submission."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"image_id\": image_ids,\n",
    "    \"soil_label\": predictions\n",
    "})\n",
    "submission.to_csv(\"submission.csv\", index=False)\n",
    "print(\"\\nSubmission file created: âœ…\")\n",
    "print(submission.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## ğŸ“ Notes\n- The model uses a pre-trained ResNet18 with weights loaded from `soil_classifier.pth`. ğŸ§ \n- Ensure the dataset paths are correct for your environment (e.g., `/content/soil_competition-2025-2`). ğŸ“‚\n- The submission file (`submission.csv`) is saved in the working directory for Kaggle submission. ğŸš€"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}